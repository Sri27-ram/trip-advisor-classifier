{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d1ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os \n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "477efe13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20491, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Datasets/tripadvisor_hotel_reviews.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5e4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")\n",
    "port = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv) \n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1af2a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice previous reviews did valet parking, check quick easy, little disappointed non-existent view room room clean nice size, bed comfortable woke stiff neck high pillows, not soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway, maybe just noisy neighbors, aveda bath products nice, did not goldfish stay nice touch taken advantage staying longer, location great walking distance shopping, overall nice experience having pay 40 parking night,  \"'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(stream_docs(path=\"Datasets/tripadvisor_hotel_reviews.csv\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b969767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream,size):\n",
    "    docs,y = [] , []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text,label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None,None\n",
    "    return docs,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a9b78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "vect = HashingVectorizer(decode_error=\"ignore\",\n",
    "                        n_features=2**21,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "clf = SGDClassifier(loss=\"log\",\n",
    "                   random_state=1,\n",
    "                   max_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9593d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array([1,2,3,4,5])\n",
    "for _ in range(45):\n",
    "    X_train,y_train = get_minibatch(stream_docs(path=\"Datasets/tripadvisor_hotel_reviews.csv\"),size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train,y_train,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e823ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.992\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: {}\".format(clf.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ce83948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.7985\n"
     ]
    }
   ],
   "source": [
    "X_test,y_test = get_minibatch(stream_docs(path=\"Datasets/tripadvisor_hotel_reviews.csv\"),size=2000)\n",
    "X_test = vect.transform(X_test)\n",
    "print(\"Prediction: {}\".format(clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4eac1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93d7c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join('classifier', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)   \n",
    "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53a24d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing classifier/vectorizer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile classifier/vectorizer.py\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "cur_dir = os.path.dirname(__file__)\n",
    "stop = pickle.load(open(\n",
    "                os.path.join(cur_dir, \n",
    "                'pkl_objects', \n",
    "                'stopwords.pkl'), 'rb'))\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "                   + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38307dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddbba458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re \n",
    "import os \n",
    "from vectorizer import vect\n",
    "\n",
    "clf = pickle.load(open(os.path.join(\"pkl_objects\",\"classifier.pkl\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24975609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: best \n",
      "Probability: 73.58510469989795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "label={1:\"worse\",2:\"bad\",3:\"good\",4:\"better\",5:\"best\"}\n",
    "example = ['I love this place']\n",
    "X = vect.transform(example)\n",
    "print(\"Prediction: {} \\nProbability: {}\".format(label[clf.predict(X)[0]],\n",
    "                                               np.max(clf.predict_proba(X)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3c118e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "conn = sqlite3.connect('reviews.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('DROP TABLE IF EXISTS review_db')\n",
    "c.execute('CREATE TABLE review_db (review TEXT, sentiment INTEGER, date TEXT)')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39ed8332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I love this place', 5, '2021-11-21 09:09:09'), ('I dislike this place', 1, '2021-11-21 09:09:09')]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"reviews.sqlite\")\n",
    "c = conn.cursor()\n",
    "# example1 = \"I love this place\"\n",
    "\n",
    "# c.execute(\"INSERT INTO review_db\"\\\n",
    "#          \" (review, sentiment, date) VALUES\"\\\n",
    "#          \" (?, ?, DATETIME('now'))\",(example1,5))\n",
    "\n",
    "# example2 = \"I dislike this place\"\n",
    "\n",
    "# c.execute(\"INSERT INTO review_db\"\\\n",
    "#          \" (review, sentiment, date) VALUES\"\\\n",
    "#          \" (?, ?, DATETIME('now'))\",(example2,1))\n",
    "# conn.commit()\n",
    "\n",
    "c.execute(\"SELECT * from review_db\")\n",
    "results = c.fetchall()\n",
    "conn.close\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf2dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
